{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7391,"databundleVersionId":44328,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-23T04:24:18.215751Z","iopub.execute_input":"2024-05-23T04:24:18.216447Z","iopub.status.idle":"2024-05-23T04:24:19.434387Z","shell.execute_reply.started":"2024-05-23T04:24:18.216407Z","shell.execute_reply":"2024-05-23T04:24:19.433434Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/favorita-grocery-sales-forecasting/test.csv.7z\n/kaggle/input/favorita-grocery-sales-forecasting/stores.csv.7z\n/kaggle/input/favorita-grocery-sales-forecasting/items.csv.7z\n/kaggle/input/favorita-grocery-sales-forecasting/holidays_events.csv.7z\n/kaggle/input/favorita-grocery-sales-forecasting/transactions.csv.7z\n/kaggle/input/favorita-grocery-sales-forecasting/train.csv.7z\n/kaggle/input/favorita-grocery-sales-forecasting/oil.csv.7z\n/kaggle/input/favorita-grocery-sales-forecasting/sample_submission.csv.7z\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Favorita Grocery Forecast\nThis notebook contains code to run a toy model version forecast for the Favorita Grocery Kaggle competition","metadata":{}},{"cell_type":"code","source":"!pip install py7zr\n!pip install duckdb","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:24:19.436167Z","iopub.execute_input":"2024-05-23T04:24:19.437203Z","iopub.status.idle":"2024-05-23T04:24:56.171829Z","shell.execute_reply.started":"2024-05-23T04:24:19.437162Z","shell.execute_reply":"2024-05-23T04:24:56.170754Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting py7zr\n  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr)\n  Downloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\nDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\nSuccessfully installed inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.16.0\nCollecting duckdb\n  Downloading duckdb-0.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (763 bytes)\nDownloading duckdb-0.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: duckdb\nSuccessfully installed duckdb-0.10.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from plotnine import *\nimport py7zr\nimport duckdb\nfrom random import sample\npd.set_option('display.max_rows', 500)\nimport lightgbm as lgb\nimport datetime\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:24:56.174598Z","iopub.execute_input":"2024-05-23T04:24:56.175002Z","iopub.status.idle":"2024-05-23T04:24:59.052554Z","shell.execute_reply.started":"2024-05-23T04:24:56.174969Z","shell.execute_reply":"2024-05-23T04:24:59.051246Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Loop through zip files and unzip","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/favorita-grocery-sales-forecasting'):\n    for filename in filenames:\n        archive = py7zr.SevenZipFile(os.path.join(dirname, filename), mode='r')\n        archive.extractall(path=\"/kaggle/working\")\n        archive.close()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:24:59.056758Z","iopub.execute_input":"2024-05-23T04:24:59.057693Z","iopub.status.idle":"2024-05-23T04:26:30.641188Z","shell.execute_reply.started":"2024-05-23T04:24:59.057620Z","shell.execute_reply":"2024-05-23T04:26:30.639542Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Read unzipped csvs into Pandas","metadata":{}},{"cell_type":"code","source":"items_df = pd.read_csv('/kaggle/working/items.csv')\ntrans_df = pd.read_csv('/kaggle/working/transactions.csv') \noil_df = pd.read_csv('/kaggle/working/oil.csv')\nholiday_df = pd.read_csv('/kaggle/working/holidays_events.csv')\nstores_df = pd.read_csv('/kaggle/working/stores.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:26:30.642746Z","iopub.execute_input":"2024-05-23T04:26:30.643830Z","iopub.status.idle":"2024-05-23T04:26:30.725065Z","shell.execute_reply.started":"2024-05-23T04:26:30.643793Z","shell.execute_reply":"2024-05-23T04:26:30.723620Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Read in training and test sets","metadata":{}},{"cell_type":"code","source":" df_train = pd.read_csv(\n        '/kaggle/working/train.csv', usecols=[0, 1, 2, 3, 4, 5],\n        dtype={'onpromotion': bool},\n#         converters={'unit_sales': lambda u: np.log1p(\n#             float(u)) if float(u) > 0 else 0},\n        parse_dates=[\"date\"],\n        skiprows=range(1, 66458909)  # 2016-01-01\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:26:30.726896Z","iopub.execute_input":"2024-05-23T04:26:30.727559Z","iopub.status.idle":"2024-05-23T04:33:41.279820Z","shell.execute_reply.started":"2024-05-23T04:26:30.727512Z","shell.execute_reply":"2024-05-23T04:33:41.278273Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\n        \"/kaggle/working/test.csv\", \n#     usecols=[0, 1, 2, 3, 4],\n        dtype={'onpromotion': bool},\n        parse_dates=[\"date\"]  # , date_parser=parser\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:33:41.282231Z","iopub.execute_input":"2024-05-23T04:33:41.283510Z","iopub.status.idle":"2024-05-23T04:33:59.498750Z","shell.execute_reply.started":"2024-05-23T04:33:41.283463Z","shell.execute_reply":"2024-05-23T04:33:59.497401Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# df_train.groupby('onpromotion').count()\ndf_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:41:16.279100Z","iopub.execute_input":"2024-05-23T04:41:16.279656Z","iopub.status.idle":"2024-05-23T04:41:16.288001Z","shell.execute_reply.started":"2024-05-23T04:41:16.279603Z","shell.execute_reply":"2024-05-23T04:41:16.286876Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"id                      int64\ndate           datetime64[ns]\nstore_nbr               int64\nitem_nbr                int64\nunit_sales            float64\nonpromotion              bool\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# dfs = df_train[(df_train.item_nbr==105574) &(df_train.store_nbr==25)]","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:33:59.508711Z","iopub.execute_input":"2024-05-23T04:33:59.509114Z","iopub.status.idle":"2024-05-23T04:33:59.518557Z","shell.execute_reply.started":"2024-05-23T04:33:59.509082Z","shell.execute_reply":"2024-05-23T04:33:59.517697Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# dft = df_train[(df_train.item_nbr==105574) &(df_train.store_nbr==25)]","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:33:59.523712Z","iopub.execute_input":"2024-05-23T04:33:59.524433Z","iopub.status.idle":"2024-05-23T04:33:59.530640Z","shell.execute_reply.started":"2024-05-23T04:33:59.524396Z","shell.execute_reply":"2024-05-23T04:33:59.529437Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Firstly:  Sample a few items to train faster. \nDays with no sales data for that item and store have no row - we want this date to exist in the dataset with a 0 for unit sales. In order to do this I found the first date the product had sales data for that store, then calculated all days from then, then left join the sales data\nand fill zeroes for missing rows in sales data","metadata":{}},{"cell_type":"code","source":"# item_nbr = 2087978\n# store_nbr=54\n# dfs = duckdb.sql(\"select * from df_train where item_nbr = {} and store_nbr={}\".format(item_nbr, store_nbr)).df()\n# item_sample = sample(list(items_df['item_nbr'].unique()), 5)\n# store_sample = sample(list(stores_df['store_nbr'].unique()), 5)\n# dfs = df_train[(df_train.item_nbr.isin(item_sample)) & (df_train.store_nbr.isin(store_sample))]\ndfs=df_train\n\nmin_dates = dfs.groupby(['item_nbr', 'store_nbr']).agg({'date':'min'}).reset_index().sort_values(['item_nbr','store_nbr'],ascending=True)\nall_dates_df = pd.DataFrame({'date':pd.date_range(start='2013-01-01', end='2017-08-15')})\nall_dates_df.head(2)\n\n\ncond_join= '''\n    select \n        m.item_nbr, m.store_nbr,\n        a.date\n    from min_dates as m\n    left join all_dates_df as a\n    on\n        m.date <= a.date\n\n'''\n# Now join sales data on to all dates\nall_min_df = duckdb.sql(cond_join).df()\nsales_join_query = '''\nselect a.date,a.item_nbr,a.store_nbr,t.unit_sales, t.onpromotion\nfrom all_min_df as a \nleft join dfs t\non a.item_nbr=t.item_nbr\nand a.store_nbr=t.store_nbr\nand a.date=t.date\norder by 2,3,1\n'''\ntrain_df2 = duckdb.sql(sales_join_query).df()\ntrain_df2['unit_sales'].fillna(0, inplace=True)\ntrain_df2['onpromotion'].fillna(False, inplace=True)\n\ntrain_df2['date'] = pd.to_datetime(train_df2['date'], format='%Y-%m-%d')\n# train_df2.sort_values('date',inplace=True)\n# train_df2.plot(x='date',y='unit_sales', title='Item {} & Store {}'.format(item_nbr, store_nbr))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:33:59.532375Z","iopub.execute_input":"2024-05-23T04:33:59.532718Z","iopub.status.idle":"2024-05-23T04:35:26.626510Z","shell.execute_reply.started":"2024-05-23T04:33:59.532689Z","shell.execute_reply":"2024-05-23T04:35:26.624969Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c2e61bdace046ed8e6fe367b1acdc53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bd192be425947bbb77a0f753cb75c0f"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_33/94774271.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n/tmp/ipykernel_33/94774271.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n/tmp/ipykernel_33/94774271.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Example of test used to find parameters for ARIMA model. In this case the very low p-value means the time series is not stationary.","metadata":{}},{"cell_type":"code","source":"# from statsmodels.tsa.stattools import adfuller\n# result = adfuller(dfs['unit_sales'])\n# print('ADF Statistic: %f' % result[0])\n# print('p-value: %f' % result[1])\n# print('Critical Values:')\n# for key, value in result[4].items():\n#   print('\\t%s: %.3f' % (key, value))","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:26.628518Z","iopub.execute_input":"2024-05-23T04:35:26.628926Z","iopub.status.idle":"2024-05-23T04:35:26.635304Z","shell.execute_reply.started":"2024-05-23T04:35:26.628892Z","shell.execute_reply":"2024-05-23T04:35:26.633726Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Use these plots for further investigation to ARIMA parameters","metadata":{}},{"cell_type":"code","source":"# plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n \n# # Original Series\n# fig, (ax1, ax2, ax3) = plt.subplots(3)\n# ax1.plot(dfs.unit_sales); ax1.set_title('Original Series'); ax1.axes.xaxis.set_visible(False)\n# # 1st Differencing\n# ax2.plot(dfs.unit_sales.diff()); ax2.set_title('1st Order Differencing'); ax2.axes.xaxis.set_visible(False)\n# # 2nd Differencing\n# ax3.plot(dfs.unit_sales.diff().diff()); ax3.set_title('2nd Order Differencing')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:26.636804Z","iopub.execute_input":"2024-05-23T04:35:26.637123Z","iopub.status.idle":"2024-05-23T04:35:26.646801Z","shell.execute_reply.started":"2024-05-23T04:35:26.637095Z","shell.execute_reply":"2024-05-23T04:35:26.645300Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"store_sample = sample(list(train_df2['store_nbr'].unique()), 3)\nitem_sample = sample(list(train_df2[train_df2.store_nbr.isin(store_sample)]['item_nbr'].unique()), 5)\ntrain_df2a = train_df2[(train_df2.item_nbr.isin(item_sample)) & (train_df2.store_nbr.isin(store_sample))]","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:26.648016Z","iopub.execute_input":"2024-05-23T04:35:26.648352Z","iopub.status.idle":"2024-05-23T04:35:30.561242Z","shell.execute_reply.started":"2024-05-23T04:35:26.648325Z","shell.execute_reply":"2024-05-23T04:35:30.560093Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# join store and item information to table\nitem_join = '''\nselect t.*, i.family, i.class, i.perishable\nfrom train_df2a t\nleft join items_df i\non t.item_nbr = i.item_nbr\n'''\ntrain_df3 = duckdb.sql(item_join).df()\n\nstore_query = '''\nselect *\nfrom train_df3 t\nleft join stores_df s\non t.store_nbr = s.store_nbr\n'''\ntrain_df4 = duckdb.sql(store_query).df()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.563291Z","iopub.execute_input":"2024-05-23T04:35:30.564080Z","iopub.status.idle":"2024-05-23T04:35:30.608317Z","shell.execute_reply.started":"2024-05-23T04:35:30.564035Z","shell.execute_reply":"2024-05-23T04:35:30.606885Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# iter_df = train_df4.head(10).assign(row_number=range(10))\n# piv = iter_df.pivot(values='unit_sales', index=['item_nbr','store_nbr','family','class','perishable','city','state','type','cluster'], \n#                          columns=\"row_number\").reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.610686Z","iopub.execute_input":"2024-05-23T04:35:30.611176Z","iopub.status.idle":"2024-05-23T04:35:30.616953Z","shell.execute_reply.started":"2024-05-23T04:35:30.611132Z","shell.execute_reply":"2024-05-23T04:35:30.615749Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# train_df4.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.618251Z","iopub.execute_input":"2024-05-23T04:35:30.618619Z","iopub.status.idle":"2024-05-23T04:35:30.628592Z","shell.execute_reply.started":"2024-05-23T04:35:30.618578Z","shell.execute_reply":"2024-05-23T04:35:30.627768Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# dd = piv.to_dict()\n# dd['date'] = '2017-07-09'\n# pd.DataFrame(dd)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.629894Z","iopub.execute_input":"2024-05-23T04:35:30.630904Z","iopub.status.idle":"2024-05-23T04:35:30.641602Z","shell.execute_reply.started":"2024-05-23T04:35:30.630866Z","shell.execute_reply":"2024-05-23T04:35:30.640428Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# iter_df.assign(row_number=range(len(iter_df)))\n# dd = {'2017-01-01':piv.values}","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.643516Z","iopub.execute_input":"2024-05-23T04:35:30.644663Z","iopub.status.idle":"2024-05-23T04:35:30.653521Z","shell.execute_reply.started":"2024-05-23T04:35:30.644593Z","shell.execute_reply":"2024-05-23T04:35:30.652134Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"We want to create training rows that consist of a single day to predict, y=unit_sales for that day. We take the 21 days of unit_sales prior to that day as features to predict y by iterating through the days, taking 21 days of data prior to each y. These rows now make up our training set","metadata":{}},{"cell_type":"code","source":"# sample item store pairs\n# train_df4[['item_nbr', 'store_nbr']].drop_duplicates().sample(n=10)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.655967Z","iopub.execute_input":"2024-05-23T04:35:30.656393Z","iopub.status.idle":"2024-05-23T04:35:30.664026Z","shell.execute_reply.started":"2024-05-23T04:35:30.656358Z","shell.execute_reply":"2024-05-23T04:35:30.662920Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"This step is very computationally intensive - I am running out of memory in this notebook. ","metadata":{}},{"cell_type":"code","source":"from datetime import timedelta, date","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.665731Z","iopub.execute_input":"2024-05-23T04:35:30.666583Z","iopub.status.idle":"2024-05-23T04:35:30.676891Z","shell.execute_reply.started":"2024-05-23T04:35:30.666549Z","shell.execute_reply":"2024-05-23T04:35:30.675607Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"n_days = 15 # length of time period to use in model\ndf_list = []\nfor m in item_sample:\n    for j in store_sample:\n        if len(train_df4[(train_df4.item_nbr==m) & (train_df4.store_nbr==j)]) == 0:\n            print('no data:', m,',', j)\n            break\n        train_df5 = train_df4[(train_df4.item_nbr==m) & (train_df4.store_nbr==j)]\n        start_date = min(train_df5['date']) + timedelta(days=n_days)\n        end_date = max(train_df5['date'])\n        a = pd.date_range(start=start_date, end=end_date)\n\n        # display only date using date() function\n        # for i in a:\n        #     print(i.date())\n\n        for i in a:\n            iter_df = train_df5[(train_df5.date<=i) & (train_df5.date >= (i-timedelta(days=n_days)))]\n        #     pivot this dataset so that the unit_sales on day i is y, and prior n days sales are columns\n            iter_df = iter_df.assign(row_number=range(len(iter_df)))\n            iter_df['row_name'] = 'row_' + iter_df['row_number'].astype(str)\n            iter_df2 = iter_df.pivot(values='unit_sales', \n                                     index=['item_nbr','store_nbr','family','class','perishable','city','state','type','cluster'], \n                                     columns='row_name').reset_index()\n            iter_df2['y_date'] = i\n            df_list.append(iter_df2)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:30.678258Z","iopub.execute_input":"2024-05-23T04:35:30.679197Z","iopub.status.idle":"2024-05-23T04:35:51.272476Z","shell.execute_reply.started":"2024-05-23T04:35:30.679162Z","shell.execute_reply":"2024-05-23T04:35:51.271069Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"no data: 2028335 , 10\nno data: 634054 , 40\nno data: 252972 , 40\nno data: 2026959 , 40\n","output_type":"stream"}]},{"cell_type":"code","source":"new_df = pd.concat(df_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.274297Z","iopub.execute_input":"2024-05-23T04:35:51.274701Z","iopub.status.idle":"2024-05-23T04:35:51.683961Z","shell.execute_reply.started":"2024-05-23T04:35:51.274658Z","shell.execute_reply":"2024-05-23T04:35:51.683004Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# new_df.store_nbr.unique()\n# new_df.item_nbr.unique()\n# item_sample, store_sample","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.685233Z","iopub.execute_input":"2024-05-23T04:35:51.686018Z","iopub.status.idle":"2024-05-23T04:35:51.689999Z","shell.execute_reply.started":"2024-05-23T04:35:51.685986Z","shell.execute_reply":"2024-05-23T04:35:51.689099Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Create dummy variables for categorical variables (although for the toy version we don't have multiple values across any of these), but leaving this code in for future use when considering more items and stores.","metadata":{}},{"cell_type":"code","source":"new_df2 = pd.get_dummies(new_df, columns=[\n    'store_nbr', \n    'item_nbr',\n    'family',\n    'class',\n    'perishable',\n    'city',\n    'state',\n    'type',\n    'cluster'\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.691373Z","iopub.execute_input":"2024-05-23T04:35:51.692156Z","iopub.status.idle":"2024-05-23T04:35:51.715379Z","shell.execute_reply.started":"2024-05-23T04:35:51.692090Z","shell.execute_reply":"2024-05-23T04:35:51.714146Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"new_df2.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.718599Z","iopub.execute_input":"2024-05-23T04:35:51.719104Z","iopub.status.idle":"2024-05-23T04:35:51.756021Z","shell.execute_reply.started":"2024-05-23T04:35:51.719072Z","shell.execute_reply":"2024-05-23T04:35:51.754576Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   row_0  row_1  row_10  row_11  row_12  row_13  row_14  row_15  row_2  row_3  \\\n0    3.0    0.0     0.0     1.0     1.0     7.0     0.0     1.0    2.0    4.0   \n0    0.0    2.0     1.0     1.0     7.0     0.0     1.0     1.0    4.0    2.0   \n\n   ...  perishable_1  city_Machala  city_Quito  state_El Oro  state_Pichincha  \\\n0  ...         False          True       False          True            False   \n0  ...         False          True       False          True            False   \n\n   type_A type_C  cluster_3  cluster_11  cluster_15  \n0   False   True       True       False       False  \n0   False   True       True       False       False  \n\n[2 rows x 37 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_0</th>\n      <th>row_1</th>\n      <th>row_10</th>\n      <th>row_11</th>\n      <th>row_12</th>\n      <th>row_13</th>\n      <th>row_14</th>\n      <th>row_15</th>\n      <th>row_2</th>\n      <th>row_3</th>\n      <th>...</th>\n      <th>perishable_1</th>\n      <th>city_Machala</th>\n      <th>city_Quito</th>\n      <th>state_El Oro</th>\n      <th>state_Pichincha</th>\n      <th>type_A</th>\n      <th>type_C</th>\n      <th>cluster_3</th>\n      <th>cluster_11</th>\n      <th>cluster_15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 37 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# new_df2.dtypes\n# max(new_df2.y_date)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.757792Z","iopub.execute_input":"2024-05-23T04:35:51.758161Z","iopub.status.idle":"2024-05-23T04:35:51.764071Z","shell.execute_reply.started":"2024-05-23T04:35:51.758133Z","shell.execute_reply":"2024-05-23T04:35:51.762409Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Lightgbm model\n# Prepare data\n# df = pd.get_dummies(train_df2, columns=['store_nbr', 'item_nbr'])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.772208Z","iopub.execute_input":"2024-05-23T04:35:51.772677Z","iopub.status.idle":"2024-05-23T04:35:51.777562Z","shell.execute_reply.started":"2024-05-23T04:35:51.772628Z","shell.execute_reply":"2024-05-23T04:35:51.776590Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"SMAPE is the Symmetric Mean Absolute Percentage Error. We use this to penalize high errors in relation to the total for that item. Eg. We want to penalize % errors but not total value errors.","metadata":{}},{"cell_type":"code","source":"def smape(preds, target):\n    n = len(preds)\n    masked_arr = ~((preds == 0) & (target == 0))\n    preds, target = preds[masked_arr], target[masked_arr]\n    num = np.abs(preds - target)\n    denom = np.abs(preds) + np.abs(target)\n    smape_val = (200 * np.sum(num / denom)) / n\n    return smape_val\n\n\ndef lgbm_smape(preds, train_data):\n    labels = train_data.get_label()\n    smape_val = smape(preds, labels)\n    return 'SMAPE', smape_val, False","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.778819Z","iopub.execute_input":"2024-05-23T04:35:51.779383Z","iopub.status.idle":"2024-05-23T04:35:51.790447Z","shell.execute_reply.started":"2024-05-23T04:35:51.779351Z","shell.execute_reply":"2024-05-23T04:35:51.788940Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train = new_df2[new_df2['y_date'].dt.date<= datetime.date(2017, 7, 30)]\ntest = new_df2[new_df2['y_date'].dt.date >  datetime.date(2017, 7, 30)]","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.792077Z","iopub.execute_input":"2024-05-23T04:35:51.792414Z","iopub.status.idle":"2024-05-23T04:35:51.813601Z","shell.execute_reply.started":"2024-05-23T04:35:51.792386Z","shell.execute_reply":"2024-05-23T04:35:51.812197Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.815351Z","iopub.execute_input":"2024-05-23T04:35:51.815749Z","iopub.status.idle":"2024-05-23T04:35:51.823954Z","shell.execute_reply.started":"2024-05-23T04:35:51.815718Z","shell.execute_reply":"2024-05-23T04:35:51.822936Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Index(['row_0', 'row_1', 'row_10', 'row_11', 'row_12', 'row_13', 'row_14',\n       'row_15', 'row_2', 'row_3', 'row_4', 'row_5', 'row_6', 'row_7', 'row_8',\n       'row_9', 'y_date', 'store_nbr_10', 'store_nbr_40', 'store_nbr_45',\n       'item_nbr_1235365', 'item_nbr_2028335', 'family_DAIRY',\n       'family_GROCERY I', 'class_1092', 'class_2166', 'perishable_0',\n       'perishable_1', 'city_Machala', 'city_Quito', 'state_El Oro',\n       'state_Pichincha', 'type_A', 'type_C', 'cluster_3', 'cluster_11',\n       'cluster_15'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"cols = [col for col in train.columns if ((col!='row_15') & (col!='y_date'))  ]\n# y_cols = [col for col in train.columns if col =='row']","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.825270Z","iopub.execute_input":"2024-05-23T04:35:51.826261Z","iopub.status.idle":"2024-05-23T04:35:51.833028Z","shell.execute_reply.started":"2024-05-23T04:35:51.826197Z","shell.execute_reply":"2024-05-23T04:35:51.832059Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# cols","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.834819Z","iopub.execute_input":"2024-05-23T04:35:51.836026Z","iopub.status.idle":"2024-05-23T04:35:51.843221Z","shell.execute_reply.started":"2024-05-23T04:35:51.835974Z","shell.execute_reply":"2024-05-23T04:35:51.842256Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"Y_train = train['row_15'].values\nX_train = train[cols]\n\nY_val = test['row_15'].values\nX_val = test[cols]","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.844800Z","iopub.execute_input":"2024-05-23T04:35:51.845407Z","iopub.status.idle":"2024-05-23T04:35:51.858908Z","shell.execute_reply.started":"2024-05-23T04:35:51.845375Z","shell.execute_reply":"2024-05-23T04:35:51.857855Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# X_train.dtypes\n# Y_train","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.860426Z","iopub.execute_input":"2024-05-23T04:35:51.861183Z","iopub.status.idle":"2024-05-23T04:35:51.868509Z","shell.execute_reply.started":"2024-05-23T04:35:51.861150Z","shell.execute_reply":"2024-05-23T04:35:51.867446Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Y_train\nY_train.shape, X_train.shape, Y_val.shape, X_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.869821Z","iopub.execute_input":"2024-05-23T04:35:51.870758Z","iopub.status.idle":"2024-05-23T04:35:51.884063Z","shell.execute_reply.started":"2024-05-23T04:35:51.870723Z","shell.execute_reply":"2024-05-23T04:35:51.882728Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"((1947,), (1947, 35), (64,), (64, 35))"},"metadata":{}}]},{"cell_type":"code","source":"# X_train","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.885880Z","iopub.execute_input":"2024-05-23T04:35:51.886396Z","iopub.status.idle":"2024-05-23T04:35:51.893258Z","shell.execute_reply.started":"2024-05-23T04:35:51.886352Z","shell.execute_reply":"2024-05-23T04:35:51.891836Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"lgb_params = {'num_leaves': 10,\n              'objective': 'regression',\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8,\n              'max_depth': 5,\n              'verbose': 0,\n              'num_boost_round': 1000,\n              'early_stopping_rounds': 200,\n              'nthread': -1}","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.894795Z","iopub.execute_input":"2024-05-23T04:35:51.895686Z","iopub.status.idle":"2024-05-23T04:35:51.904560Z","shell.execute_reply.started":"2024-05-23T04:35:51.895636Z","shell.execute_reply":"2024-05-23T04:35:51.903174Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# lgb_params['early_stopping_rounds']","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.906341Z","iopub.execute_input":"2024-05-23T04:35:51.907085Z","iopub.status.idle":"2024-05-23T04:35:51.915618Z","shell.execute_reply.started":"2024-05-23T04:35:51.907041Z","shell.execute_reply":"2024-05-23T04:35:51.914103Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"lgbtrain = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\n\nlgbval = lgb.Dataset(data=X_val, label=Y_val, reference=lgbtrain, feature_name=cols)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.917409Z","iopub.execute_input":"2024-05-23T04:35:51.918119Z","iopub.status.idle":"2024-05-23T04:35:51.927749Z","shell.execute_reply.started":"2024-05-23T04:35:51.918084Z","shell.execute_reply":"2024-05-23T04:35:51.926593Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model = lgb.train(lgb_params, lgbtrain,\n                  valid_sets=[lgbtrain, lgbval],\n                  num_boost_round=lgb_params['num_boost_round'],\n#                   early_stopping_rounds=lgb_params['early_stopping_rounds'],\n                  feval=lgbm_smape\n#                   verbose_eval=100\n                 )","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:51.929314Z","iopub.execute_input":"2024-05-23T04:35:51.929881Z","iopub.status.idle":"2024-05-23T04:35:52.767336Z","shell.execute_reply.started":"2024-05-23T04:35:51.929852Z","shell.execute_reply":"2024-05-23T04:35:52.766018Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:52.768864Z","iopub.execute_input":"2024-05-23T04:35:52.769249Z","iopub.status.idle":"2024-05-23T04:35:52.782149Z","shell.execute_reply.started":"2024-05-23T04:35:52.769218Z","shell.execute_reply":"2024-05-23T04:35:52.780733Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n# RMSLE\n\nmean_squared_log_error(Y_val, y_pred_val, squared=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:52.784345Z","iopub.execute_input":"2024-05-23T04:35:52.786890Z","iopub.status.idle":"2024-05-23T04:35:52.800611Z","shell.execute_reply.started":"2024-05-23T04:35:52.786843Z","shell.execute_reply":"2024-05-23T04:35:52.799245Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0.633504461774297"},"metadata":{}}]},{"cell_type":"code","source":"# Plot the actual and predicted for a single item and store\nplot_df = pd.DataFrame({'y':Y_val[(X_val.item_nbr_658609) & (X_val.store_nbr_46)], 'y_pred':y_pred_val[(X_val.item_nbr_658609) & (X_val.store_nbr_46)]})\nplt.plot(plot_df.y)\nplt.plot(plot_df.y_pred,color='red')","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:52.802859Z","iopub.execute_input":"2024-05-23T04:35:52.803345Z","iopub.status.idle":"2024-05-23T04:35:53.123199Z","shell.execute_reply.started":"2024-05-23T04:35:52.803303Z","shell.execute_reply":"2024-05-23T04:35:53.121237Z"},"trusted":true},"execution_count":44,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/71976682.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the actual and predicted for a single item and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_nbr_658609\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_nbr_46\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_pred_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_nbr_658609\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_nbr_46\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'item_nbr_658609'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'item_nbr_658609'","output_type":"error"}]},{"cell_type":"code","source":"def plot_lgb_importances(model, plot=False, num=10):\n    gain = model.feature_importance('gain')\n    feat_imp = pd.DataFrame({'feature': model.feature_name(),\n                             'split': model.feature_importance('split'),\n                             'gain': 100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n    if plot:\n        plt.figure(figsize=(10, 10))\n        sns.set(font_scale=1)\n        sns.barplot(x=\"gain\", y=\"feature\", data=feat_imp[0:25])\n        plt.title('feature')\n        plt.tight_layout()\n        plt.show(block=True)\n    else:\n        print(feat_imp.head(num))\n    return feat_imp","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:53.124742Z","iopub.status.idle":"2024-05-23T04:35:53.125212Z","shell.execute_reply.started":"2024-05-23T04:35:53.124980Z","shell.execute_reply":"2024-05-23T04:35:53.125014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplot_lgb_importances(model, num=30, plot=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T04:35:53.131881Z","iopub.status.idle":"2024-05-23T04:35:53.132366Z","shell.execute_reply.started":"2024-05-23T04:35:53.132156Z","shell.execute_reply":"2024-05-23T04:35:53.132174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next step would be to iterate over a 16 day period - currently this model is only predicting a single day ahead.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}